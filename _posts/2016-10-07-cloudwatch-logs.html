---
layout: blog
subtitle: "Introducing AWS CloudWatch Logs support with Live Tailing"
permalink: /blog/cloudwatch-logs.html
---
<p>Logging provides critically important visibility into the inner workings
    of our applications and offers a great way to perform both live and post-mortem analysis of interactions with our
    systems.</p>

<p>To be able to enjoy those benefits effectively a logging solution must possess a number of important qualities including
    <em>durability</em>, <em>security</em>, <em>availability</em>, <em>searchability</em> and <em>speed</em>.</p>

<p>We must also distinguish between two important <a href="/blog/logging-cloudnative">types of logs</a>: <em>instance
    boot logs</em> and <em>application logs</em>.</p>

<p><strong>Instance boot logs</strong> collect information from the earliest stages of instance startup (bootloader and
    kernel boot) all the way to the point where the application is fully configured and ready to start shipping log events
    to the logging service of our choice.
    This makes instance boot logs great for identifying early environment-specific
    network and application configuration issues that may prevent an application from coming up correctly and start logging them in the first place.</p>

<p><strong>Application logs</strong> are all the logs produced by our application from that point on.</p>

<p>For the latter Boxfuse provided no out-of-the-box solution until now and you had to rely on external solutions to fill that gap.
    Today we are <strong>introducing first class AWS CloudWatch Logs integration</strong> to close this gap.</p>

<img class="blog-post-image" src="/assets/img/cloudwatch-logs.png">

<p>So without further ado, let's dive in and look at it in more detail!</p>

<h2>Centralized Logging</h2>

<p>In a modern microservices and cloud architecture, a single client request can end up traversing multiple services.
    Each of those
    services is then <a href="/blog/auto-scaling">auto-scaled</a> across a number of machines to have the appropriate
    capacity to handle the current load at all times.</p>

<p>This has a number of serious implications:</p>
<ol>
    <li>If more than one service is triggered by the request, more than one machine will produce logs related to that
        request.
    </li>
    <li>The exact machine which will handle that specific request for each service is determined in real time by
        the load-balancer and not known in advance.
    </li>
    <li>A machine which may have handled requests a few minutes ago, may now be terminated due to a change in load of
        the system having triggered a scale-in activity.
    </li>
</ol>

<p>Additionally in the world of <a href="/getstarted/why">immutable infrastructure</a> and <a href="/getstarted/how">minimal
    images</a> there
    is a strong focus on security and the principle of least privilege, which also means there is <a
            href="/blog/no-ssh">no SSH</a> on board of the running instances.</p>

<p>These realities effectively mean that application logs cannot be stored on the instance itself. Instead they must be
    shipped to a
    <strong>centralized logging service</strong> where they can then be securely stored and made available.</p>

<p>This is a great solution as it allows us to centrally enforce, enable and control a number of things.</p>

<h3>Durability</h3>

<p>Logs must be retained for the time required to perform useful analysis on them. Their value often decreases sharply
    over time. This stands
    in stark contrast to the space they occupy and the cost associated with it. It is therefore crucial to choose an
    appropriate
    <strong>retention period</strong> to strike the right balance between storage cost and historical usefulness.</p>

<p>The other important aspect of having a centralized logging service is <strong>enabling logs to outlive the machines
    that produced them</strong>.</p>

<h3>Security</h3>

<p>It is often forgotten that logs usually contain a lot of sensitive information. It crucial that the protection of
    this information be held to
    the same standards as the information present in our other systems. This means there is a shared responsibility
    here.
    On the one hand it is the responsibility of the centralized logging service to provide strong <strong>access
        controls</strong>.
    On the other hand, it is also your responsibility to carefully evaluate whether certain kinds of information maybe
    shouldn't be
    <strong>obfuscated or left out</strong> of the logs in the first place.</p>

<h3>Availability</h3>

<p>Since a load-balancer may send a request to any instance of a service and that service may in turn call many other
    services,
    a centralized logging services is a life-saver for actually finding the logs related to that request. No more
    searching for a needle
    in a haystack. Instead all the logs are <strong>available from one central place</strong>. Equally important here of
    course is the
    fact that due to auto-scaling events some of
    the machines which have produced logs may be long gone by the time someone is ready to analyse them.</p>

<h3>Searchability</h3>

<p>A centralized logging service makes it trivial to <strong>search all logs in one go</strong>. This includes all the
    logs produced by
    all instances
    of all services within an <a href="/docs/environments">environment</a>. This makes it possible to easily obtain all
    the logs
    for things like:</p>
<ul>
    <li>a single request across services</li>
    <li>all sessions for a single user across one or more services</li>
    <li>all instances of an application</li>
</ul>
<p>And many more!</p>

<h3>Speed</h3>
<p>Of course to be usable a centralized logging service must also come with logging agents installed on the clients that
    produce
    as little runtime performance overhead as possible. For this it is essential that the sending of logs events to the
    service be
    <strong>asynchronous</strong> and <strong>non-blocking</strong> to the regular request processing flow. In a lot of
    cases today the network
    is actually very reliable and fast. Smart batching in memory virtually eliminates the need for on-disk buffering
    which is often slower than sending the events directly over network as the disks often aren't local anyway!</p>

<h2>AWS CloudWatch Logs</h2>

<p>So far in order to use a centralized logging service with Boxfuse one had to rely on an external service like Loggly,
Logentries or Papertrail, or set up their own ELK stack. AWS however also has their own service for this called
    <strong>CloudWatch Logs</strong> and Boxfuse now has first class support for it!</p>

<p>At its core CloudWatch Logs is an API for ingesting and querying log events. It revolves around three simple concepts:
<em>Log Groups</em>, <em>Log Streams</em> and <em>Log Events</em>.</p>

<h3>Log Events</h3>

<p>Log events are the actual log messages produced by your application. To be able to send those to CloudWatch Logs you
need some kind of client to talk to the CloudWatch Logs API. By default AWS provides an agent to take care of that. It is
unfortunately written in Python and comes with a long string of dependencies. In other words, it simply isn't a good
fit for Boxfuse's <a href="/getstarted/how">minimal images</a>, so we had to come up with a better solution! More about this in a minute...</p>

<h3>Log Streams</h3>

<p>Log streams are the destination where log events get sent to and can be queried from.</p>

<p>With Boxfuse, <strong>each application deployment within an environment receives its own log stream</strong>.</p>

<h3>Log Groups</h3>

<p>Log groups contain one or more log streams. Streams physically belong to a log group. Log events can also be queried
across multiple streams at once at the log group level. And log event retention can also be configured for an entire group at once.</p>

<p>With Boxfuse, <strong>each environment receives its own log group</strong>, containing all the logs streams of the applications deployed within that environment.</p>

<h2>Seeing it in action</h2>

<p>So let's see how this works in practice!</p>

<h3>Creating an app with AWS CloudWatch Logs support</h3>

<p>The first step is to create a new application configured for CloudWatch Logs:</p>

<img class="blog-post-image screenshot" src="/assets/posts/cloudwatch-logs/create.png">

<p>We could also have done the same by using the Boxfuse Client by creating an app with <a href="/docs/commandline/create#logs.type"><code>logs.type</code></a> set to <code>cloudwatch-logs</code>:</p>

<pre class="console"><span>&gt;</span> boxfuse create hello <strong>-logs.type=cloudwatch-logs</strong></pre>

<h3>Fusing an image (including automatic agent installation and configuration)</h3>

<p>As mentioned above, to be able to send events to AWS CloudWatch Logs a client is needed to talk to the API and unfortunately the official AWS agent doesn't cut it.</p>

<p>We are therefore today releasing a new <strong><a href="https://github.com/boxfuse/cloudwatchlogs-agent">open-source CloudWatch Logs agent</a></strong> written in Go that is optimized to work within Boxfuse instances.</p>

<p>It has a very small footprint (3 MB) and is designed to asynchronously redirect stdout and stderr output of an application to CloudWatch Logs.</p>

<p>Now let's fuse an image of our app:</p>

<pre class="console"><span>&gt;</span> boxfuse fuse hello.war</pre>

<p>This will <strong>automatically install both our application and the CloudWatch Logs agent</strong>. Two copies of the agent will be running. One to redirect stdout output of the application to CloudWatch logs as <code>INFO</code>
log events and the other to do the same for stderr output as <code>ERROR</code> log events.</p>

<h3>Running an instance on VirtualBox</h3>

<p>If we now run an instance of our application on VirtualBox using</p>

<pre class="console"><span>&gt;</span> boxfuse run hello:1.0</pre>

<p>Boxfuse will also automatically launch a <strong>local CloudWatch Logs mock</strong> which will be ready to ingest log events as soon as the application starts sending them.</p>

<h3>Running it on AWS</h3>

<p>If we launch an instance on AWS with</p>

<pre class="console"><span>&gt;</span> boxfuse run hello:1.0 -env=prod

...
Creating Log Group boxfuse/prod ...
Creating Log Stream boxfuse/prod > myuser/hello ...
...</pre>

<p>You'll notice that both a Log Group for the Boxfuse <code>prod</code> environment as well as a Log Stream for the <code>myuser/hello</code> app were created.
    The latter which the Boxfuse CloudWatch Logs agent installed on your instance will now start sending log events to.
Any stdout and stderr console output produced by our application will now be redirected to that log stream.</p>

<h3>Retrieving the log events</h3>

<p>To view the log events produced by our application all we need to do is</p>

<pre class="console"><span>&gt;</span> boxfuse logs hello -env=prod</pre>

<p>And you'll see the logs appearing in your terminal.</p>

<h2>Live Tailing</h2>

<p>But sometimes however it is also immensely useful to be able to follow logs in real time. And we are happy to announce
that you can now do so both on VirtualBox and on AWS by simply appending <code>-logs.tail</code> to our prevent command:</p>

<pre class="console"><span>&gt;</span> boxfuse logs hello -env=prod <strong>-logs.tail</strong></pre>

<p>Any new logs produced by your application will now immediately be shown on your machine for as long as the Boxfuse Client
    is running. We have optimized things so that logs are <strong>delivered directly from AWS to your local machine</strong>,
bypassing all Boxfuse infrastructure.</p>

<h2>Summary</h2>

<p>Boxfuse now has <strong>first-class support for AWS CloudWatch Logs</strong>. This gives you access to a centralized logging service which comes with
    durability, security, availability, searchability and speed.</p>

<p>With apps created to take advantage of this, your images are automatically fused with our brand new <strong>open-source CloudWatch Logs agent</strong>
    which is fully configured to redirect both stdout and stderr to AWS CloudWatch Logs.</p>

<p>Boxfuse also automatically starts a <strong>local CloudWatch Logs mock</strong> to provide you with the same experience when running on VirtualBox.</p>

<p>And last but not least you now have easy access to your logs, including <strong>live tailing</strong> for both VirtualBox and AWS.</p>

<p>This new feature is available at no charge to all Boxfuse users.</p>

<p>So if you haven't already,
    <a href="https://console.boxfuse.com"><strong>sign up for your
        Boxfuse account</strong></a> now (simply log in with your GitHub id, it's free) and start deploying
    your applications effortlessly to AWS in minutes and enjoy the great integration with CloudWatch Logs from the start.</p>